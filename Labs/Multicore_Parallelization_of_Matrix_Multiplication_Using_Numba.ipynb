{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "533203a6",
   "metadata": {},
   "source": [
    "# GEOPHYS 257 (Winter 2023)\n",
    "[//]: <> (Notebook Author: Thomas Cullison, Stanford University, Jan. 2023)\n",
    "\n",
    "## Multicore Parallelization of Matrix Multiplication Using Numba\n",
    "\n",
    "In this lab we will be using Numba to accelerate matrix-matrix multiplications by exploiting parallelism. Even most laptops today have Multicore CPUs, where a *core* is a microprocessor, and each core is usually a copy of the each other core. Accelerating the marrix-matrix multiplication operation is a good analog to accelerating other types of operators and computationally intense kernels, codes, and algorithms. Furthermore, the structure of matricies makes matrix-matrix multiplication a good place start learning how to parallelize code.\n",
    "\n",
    "\n",
    "## External Resources\n",
    "If you have any question regarding some specific Python functionality you can consult the official [Python documenation](http://docs.python.org/3/).\n",
    "\n",
    "* [Numba](https://numba.readthedocs.io/en/stable/index.html): Documentation\n",
    "* [Numba in 30 min](https://youtu.be/DPyPmoeUdcE): Conference presentation video\n",
    "\n",
    "\n",
    "## Required Preperation\n",
    "Please watch the following videos before starting the lab (each is pretty short):\n",
    "* [Introduction to Parallel Computing](https://youtu.be/RNVIcm8-6RE)\n",
    "* [Amdahl's Law](https://youtu.be/Axx2xuB-Xuo)\n",
    "* [CPU Caching](https://youtu.be/KmairurdiaY)\n",
    "* [Pipelining](https://youtu.be/zPmfprtdzCE)\n",
    "* [Instruction Level Parallelism](https://youtu.be/ZoDUI3gTkDI)\n",
    "* [Introduction to SIMD](https://youtu.be/o_n4AKwdfiA)\n",
    "\n",
    "\n",
    "## Exercise 0\n",
    "\n",
    "Please run the following cells.  Examine the result of the example function that makes use of the *timer* wrapper. Also please use this timer wrapper (defined below) for all the exercises that follow.\n",
    "\n",
    "### Load python modules \n",
    "#### (Note: you may need to install some Python packages for the modules below, e.g. Numba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9957106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from functools import wraps\n",
    "from time import time, sleep\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc2aac",
   "metadata": {},
   "source": [
    "### Define a function-decorator for timing the runtime of your functions\n",
    "\n",
    "Below is some code that you can use to wrap your functions so that you can time them individually.  The function defined immediately below the *timer()* is an example of how to use the warpper. In the cell that follows, execute this example function. (Note, for this timer, were are making use of something called *decorators*, but a discussion about this feature is outside the scope of this class.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd0a801",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# defining a function decorator for timing other functions\n",
    "def mytimer(func):\n",
    "    @wraps(func)\n",
    "    def wrap(*args, **kwargs):\n",
    "        t_start = time() # Students look here\n",
    "        result = func(*args, **kwargs)\n",
    "        t_end = time() # Students also look here. This is how you can time things inside functions/classes\n",
    "        print(f'Function: \\'{func.__name__}({kwargs})\\' executed in {(t_end-t_start):6.5f}s\\n')\n",
    "        return result\n",
    "    return wrap\n",
    "    \n",
    "\n",
    "# Example of how to use. NOTE the \"@mytimer\" stated just above the function definition\n",
    "@mytimer\n",
    "def example_sum_timer_wrap(N):\n",
    "    \"\"\" Sum the squares of the intergers, i, contained in [1-N] \"\"\"\n",
    "    return np.sum(np.arange(1,N+1)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cb7b5c",
   "metadata": {},
   "source": [
    "### Run the example function\n",
    "\n",
    "Run the example function for each of the following instances of $N = 10^5, 10^6, 10^7, 10^8$. Please examine the results, in particular, how the runtime changes with respect to $N$.\n",
    "\n",
    "\n",
    "**Answer** the following questions in the markdown cell that follow the code. \n",
    "* For each factor-of-ten increase in $N$, roughly how much longer was the runtime of the function?\n",
    "* Does this slowdown in the runtime make sense? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa466992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: 'example_sum_timer_wrap({'N': 100000})' executed in 0.00106s\n",
      "\n",
      "Function: 'example_sum_timer_wrap({'N': 1000000})' executed in 0.00971s\n",
      "\n",
      "Function: 'example_sum_timer_wrap({'N': 10000000})' executed in 0.09520s\n",
      "\n",
      "Function: 'example_sum_timer_wrap({'N': 100000000})' executed in 0.94551s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the example function above for each value of N (try making one-call first, then loop)\n",
    "\n",
    "N_list = 10 ** np.arange(5, 9, dtype=np.int32)\n",
    "\n",
    "for N in N_list:\n",
    "    example_sum_timer_wrap(N = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e4c88",
   "metadata": {},
   "source": [
    "### Discussion for Exercise 0 questions\n",
    "* For each factor-of-10 increase in $N$, the function runtime is also roughly 10 times longer.\n",
    "* This linear $O(N)$ slowdown makes sense. Within the function it creates a numpy array with size $N$, and the number of math operations also increases linearly with $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8161fc",
   "metadata": {},
   "source": [
    "## Exercise 1: Naive matrix multiplication: \n",
    "\n",
    "For this exercise, we will write our own matrx-matrix multiplication function.  We are goint to be naive about it, so we want to loop over individual indices, instead of using slicing (in the next section, we will parallelize this code and we want to see how well Numba does at speeding up the naive code).\n",
    "\n",
    "### Tasks for this exercise\n",
    "\n",
    "1. Write a function with that calculates matrix-matrix multiplication such that $C = A\\cdot B$, where $A$, $B$, and $C$ are 2D numpy arrays. Make the dtype for the $C$ matrix the same as the dtype for $A$. Below is a stencil you can start with. Test your results for accuracy and performance against the np.dot() function. To time the np.dot() function, you can wrap it in another function and use the *mytimer* wrapper; however, please copy the code for testing the A and B dimensions into your function wrapper for the np.dot() function. This keeps the runtime comparison as a more \"apples-to-apples\" like comparison.\n",
    "\n",
    "```python\n",
    "@mytimer\n",
    "def my_naive_matmul(A:np.ndarray, B:np.ndarray):\n",
    "    \"\"\" This is a naive matrix-multiplication function \"\"\" \n",
    "    \n",
    "    # 1. \n",
    "    # check that A and B have appropriate dimensions for multiplication\n",
    "    \n",
    "    # 2. \n",
    "    # construnct a 2D numpy array for matrix C, that is filled with zeros \n",
    "    # and that has the appropriate dimensions such that C=A*B is a valid \n",
    "    # equation and operation\n",
    "    \n",
    "    # 3\n",
    "    # Write three nested for loops, with indices, i,j,k to solve the matrix-multiplication\n",
    "    # e.g.\n",
    "    # for i in range(<val>):\n",
    "    #   for j in range(<val>):\n",
    "    #     for k in range(<val>):\n",
    "    #       C[<c_row_index>,<c_col_index>] += A[<a_row_index>,<a_col_index>]*B[<b_row_index>,<b_col_index>]\n",
    "    \n",
    "    # 4\n",
    "    # return the 2D numpy array for C\n",
    "    return C\n",
    "```\n",
    "<br>\n",
    "\n",
    "2. Define your functions in the cell below.\n",
    "3. Test and compare the accuracy and runtime of your functions in the next cell.\n",
    "    - Test with non-square Matrices: $A \\in \\mathbb{R}^{N\\times K}$ and $B \\in \\mathbb{R}^{K \\times M}$. With $N = 64$, $K = 32$, and $M = 128$.\n",
    "    - Test with a square Matrices: $A,B \\in \\mathbb{R}^{N\\times N}$. For the cases when $N = 64, 128,$ and $256$.\n",
    "    - Test the following three cases:\n",
    "        - Case-1. $A$ and $B$ **both** have dtype=np.**float32** (make sure that $C$ is also of dtype=np.**float32**)\n",
    "        - Case-2. $A$ has dtype=np.**float64**, but $B$ has dtype=np.**float32**\n",
    "        - Case-3. $A$ and $B$ **both** have dtype=np.**float64** (make sure that $C$ is also of dtype=np.**float64**)\n",
    "    - For all three case above:\n",
    "        - Calculate and show the error by computing the sum of the difference between the $C$ matrices computed from numpy.dot() and your my_naive_matmul() functions. Assume that numpy.dot() is correct\n",
    "        - Calculate and show the *speedup* that the faster function has versus the slower function.\n",
    "        - Comment on the which of the three cases is fastest, and comment on what the speedup of the fastest case is and why it is the fastest case.\n",
    "4. Create your matrices using random numbers. An example is shown below (feel free to copy this).\n",
    "\n",
    "```python\n",
    "A = np.random.rand(N, K)\n",
    "B = np.random.rand(\"for-you-to-figure-out\")\n",
    "```\n",
    "<br>\n",
    "\n",
    "### Write function definitions for Exercise 1 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6404b75",
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Define your functions for Exercise 1 here.\n",
    "\n",
    "def my_naive_matmul(A:np.ndarray, B:np.ndarray):\n",
    "    \"\"\" This is a naive matrix-multiplication function \"\"\" \n",
    "    \n",
    "    # 1. \n",
    "    # check that A and B have appropriate dimensions for multiplication\n",
    "    N, K = A.shape\n",
    "    _K, M = B.shape\n",
    "    \n",
    "    if K != _K:\n",
    "        raise ValueError('Matrices dimensions do not match for multiplication!')\n",
    "    \n",
    "    # 2. \n",
    "    # construct a 2D numpy array for matrix C, that is filled with zeros \n",
    "    # and that has the appropriate dimensions such that C=A*B is a valid \n",
    "    # equation and operation\n",
    "    C = np.zeros((N, M), dtype=A.dtype)\n",
    "    \n",
    "    # 3\n",
    "    # Write three nested for loops, with indices, i,j,k to solve the matrix-multiplication\n",
    "    for i in range(N):\n",
    "        for k in range(K):\n",
    "            for j in range(M):\n",
    "                C[i, j] += A[i, k] * B[k, j]\n",
    "    \n",
    "    # 4\n",
    "    # return the 2D numpy array for C\n",
    "    return C\n",
    "\n",
    "def np_matmul(A:np.ndarray, B:np.ndarray):\n",
    "    \"\"\" This is the matrix-multiplication function using numpy \"\"\" \n",
    "    \n",
    "    # 1. \n",
    "    # check that A and B have appropriate dimensions for multiplication\n",
    "    N, K = A.shape\n",
    "    _K, M = B.shape\n",
    "    \n",
    "    if K != _K:\n",
    "        raise ValueError('Matrices dimensions do not match for multiplication!')\n",
    "        \n",
    "    # 2. \n",
    "    # construct a 2D numpy array for matrix C, that is filled with zeros \n",
    "    # and that has the appropriate dimensions such that C=A*B is a valid \n",
    "    # equation and operation\n",
    "    C = np.zeros((N, M), dtype=A.dtype)\n",
    "    \n",
    "    # 3.\n",
    "    # calculate matrix-multiplication with np.dot()\n",
    "    np.dot(A, B, out=C)\n",
    "    \n",
    "    # 4\n",
    "    # return the 2D numpy array for C\n",
    "    return C\n",
    "\n",
    "def compare_matmul(C1:np.ndarray, C2:np.ndarray):\n",
    "    \"\"\" Calculate absolute error between two matrices \"\"\"\n",
    "    return np.sum(np.abs(C1 - C2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44a3ede6-0a14-4c12-8b13-4bfe7bb147a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for testing\n",
    "\n",
    "def test_naive_matmul(shape):\n",
    "    \"\"\" This function compares naive matrix-multiplication with np.dot() \"\"\"\n",
    "\n",
    "    # 1.\n",
    "    # Check the shape of matrix\n",
    "    if shape[0] == shape[1] and shape[1] == shape[2]:\n",
    "        print('Square matrices, N = %d' %shape[0])\n",
    "    else:\n",
    "        print('Non-square matrices, N = %d, K = %d, M = %d' %(shape[0], shape[1], shape[2]))\n",
    "        \n",
    "    # 2.\n",
    "    # Generate random matrices\n",
    "    A0 = np.random.rand(shape[0], shape[1])\n",
    "    B0 = np.random.rand(shape[1], shape[2])\n",
    "    \n",
    "    # 3.\n",
    "    # Loop over three cases with different float data types\n",
    "    for case in range(3):\n",
    "        \n",
    "        # 3.1.\n",
    "        # Float types of matrices\n",
    "        if case == 0:\n",
    "            print('\\n#1: Both A and B are float32')\n",
    "            A = A0.astype(np.float32)\n",
    "            B = B0.astype(np.float32)\n",
    "\n",
    "        elif case == 1:\n",
    "            print('\\n#2: A is float64, and B is float32')\n",
    "            A = A0.astype(np.float64)\n",
    "            B = B0.astype(np.float32)\n",
    "\n",
    "        elif case == 2:\n",
    "            print('\\n#3: Both A and B are float64')\n",
    "            A = A0.astype(np.float64)\n",
    "            B = B0.astype(np.float64)\n",
    "\n",
    "        # 3.2.\n",
    "        # Time functions: Naive matrix-multiplication and np.dot\n",
    "        t1_start = time()\n",
    "        C1 = my_naive_matmul(A, B)\n",
    "        t1_end = time()\n",
    "        t1 = t1_end - t1_start\n",
    "\n",
    "        t2_start = time()\n",
    "        C2 = np_matmul(A, B)\n",
    "        t2_end = time()\n",
    "        t2 = t2_end - t2_start\n",
    "\n",
    "        # 3.3.\n",
    "        # Calculate speed-up and accuracy\n",
    "        if (t1 >= t2):\n",
    "            print('Numpy function is faster')\n",
    "            speedup = t1 / t2\n",
    "        else:\n",
    "            print('Naive matmul is faster')\n",
    "            speedup = t2 / t1\n",
    "\n",
    "        print('Speed-up factor: %.3f' %speedup)\n",
    "        print('Error: %s' %compare_matmul(C1, C2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db232378",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Write the test codes for Exercise 1 in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea011152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-square matrices, N = 64, K = 32, M = 128\n",
      "\n",
      "#1: Both A and B are float32\n",
      "Numpy function is faster\n",
      "Speed-up factor: 2116.324\n",
      "Error: 0.0018548965\n",
      "\n",
      "#2: A is float64, and B is float32\n",
      "Numpy function is faster\n",
      "Speed-up factor: 1587.627\n",
      "Error: 3.4305891460917337e-12\n",
      "\n",
      "#3: Both A and B are float64\n",
      "Numpy function is faster\n",
      "Speed-up factor: 2000.789\n",
      "Error: 3.4128255776977312e-12\n"
     ]
    }
   ],
   "source": [
    "# Non-square matrices\n",
    "\n",
    "N = 64\n",
    "K = 32\n",
    "M = 128\n",
    "\n",
    "test_naive_matmul([N, K, M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74a400f9-0fbd-47ad-a8d6-c5e6bedca913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square matrices, N = 64\n",
      "\n",
      "#1: Both A and B are float32\n",
      "Numpy function is faster\n",
      "Speed-up factor: 2489.492\n",
      "Error: 0.0018596649\n",
      "\n",
      "#2: A is float64, and B is float32\n",
      "Numpy function is faster\n",
      "Speed-up factor: 1770.902\n",
      "Error: 3.3448799285906716e-12\n",
      "\n",
      "#3: Both A and B are float64\n",
      "Numpy function is faster\n",
      "Speed-up factor: 1634.441\n",
      "Error: 3.4425795547576854e-12\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Square matrices, N = 128\n",
      "\n",
      "#1: Both A and B are float32\n",
      "Numpy function is faster\n",
      "Speed-up factor: 6178.329\n",
      "Error: 0.014881134\n",
      "\n",
      "#2: A is float64, and B is float32\n",
      "Numpy function is faster\n",
      "Speed-up factor: 4370.316\n",
      "Error: 2.7110758082926623e-11\n",
      "\n",
      "#3: Both A and B are float64\n",
      "Numpy function is faster\n",
      "Speed-up factor: 5150.084\n",
      "Error: 2.773603569039551e-11\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Square matrices, N = 256\n",
      "\n",
      "#1: Both A and B are float32\n",
      "Numpy function is faster\n",
      "Speed-up factor: 25606.523\n",
      "Error: 0.1199913\n",
      "\n",
      "#2: A is float64, and B is float32\n",
      "Numpy function is faster\n",
      "Speed-up factor: 15987.883\n",
      "Error: 1.4313243923425034e-09\n",
      "\n",
      "#3: Both A and B are float64\n",
      "Numpy function is faster\n",
      "Speed-up factor: 16789.231\n",
      "Error: 1.4339462950374582e-09\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Square matrices\n",
    "\n",
    "for N in np.array([64, 128, 256]):\n",
    "    test_naive_matmul([N, N, N])\n",
    "    print('\\n%s\\n' %(\"-\" * 75))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae756d65",
   "metadata": {},
   "source": [
    "## Exercise 2: Using Numba to speed up matrix multiplication: \n",
    "\n",
    "For this exercise, numba to speedup our matrx-matrix multiplication function below. However, there is an interesting twist to this exercise. We will write six versions of the naive function you wrote above. One function for each of the six possible permutations of three loops used to calculate the multplication (i.e. ijk, ikj, jik, etc.)\n",
    "\n",
    "### The tasks for this exercise:\n",
    "1. Make six copies your code for the my_naive_matmul(), one copy for each of the possible permutations and define them in the cell bellow:\n",
    "    - One of these function will have the same loop order as the my_naive_matmul() function. \n",
    "    - However name these functions: numba_mul_\\<perm\\>(), where \\<perm\\> should be replaced by the specific loop order of the function.\n",
    "2. In the cell that follows your function definitions, test and compare the accuracy and runtime of your functions against the numpy.dot() function.\n",
    "    - Test with a square Matrices: $A,B \\in \\mathbb{R}^{N\\times N}$. For the cases when $N = 128, 256,$ and $512$.\n",
    "    - For each matrix set their dtype as: dtype=np.float64\n",
    "    - Calculate and show the error between your functions and the numpy.dot() function. (Same as in Exercise 1.)\n",
    "    - Calculate and show the *speedup* that the fastest function has versus all the other functions.\n",
    "    - You should notice that one of your permutation functions is faster than the others. For this case show the following:\n",
    "        - Calculate and show the *speedup* that the fastest permutation function has versus the my_naive_matmul().\n",
    "        - Calculate and show the *speedup* that the fastest permutation function has when $A$, $B$, and $C$ are all of dtype=np.float64 vs all are of dtype=np.float32.\n",
    "3. Create your matrices using random numbers. (Same as in Exercise 1.) \n",
    "4. For each function, you need to add a function decorator for numba. Numba will *JIT* the function (**J**ust **I**n **T**ime compilation). \n",
    "    - Use the flag to keep a \"cache\" of the compiled code (not to be confused with CPU cache). **Note**: to get accurate timings, you will need to run your tests **twice**, because during the first run, the code is compiled and this compile time will be included in your runtime. After the first run, the compiled binary will be stored, so consecutive runs will be faster.\n",
    "    - Use the flag to use *fast math*\n",
    "    - Use the flag to disable the Python Global Interpretor Lock (GIL).\n",
    "    - The code below should get you started, but it is incomplete.\n",
    "    \n",
    "```python   \n",
    "    \n",
    "@mytimer\n",
    "@numba.njit(<flagname_caching>=<flag>, <flagname_fast_math>=<flag>, <flagname_no_gil>=<flag>)\n",
    "def numba_mul_<perm>(A:np.ndarray, B:np.ndarray):\n",
    "    \"\"\" This is a Numba accelerated matrix-multiplication function \"\"\" \n",
    "    \n",
    "    # 1. \n",
    "    # check that A and B have appropriate dimensions for multiplication\n",
    "    \n",
    "    # 2. \n",
    "    # construnct a 2D numpy array for matrix C, that is filled with zerros \n",
    "    # and that has the appropriate dimensions such taht C=A*B is a valid \n",
    "    # equation and operation\n",
    "    \n",
    "    # 3\n",
    "    # Write three nested for loops, with indices, i,j,k to solve the matrix-multiplication\n",
    "    # e.g.\n",
    "    # for i in numba.prange(<val>): # !!!! LOOK HERE !!!!\n",
    "    #   for j in range(<val>):\n",
    "    #     for k in range(<val>):\n",
    "    #       C[<c_row_index>,<c_col_index>] += A[<a_row_index>,<a_col_index>]*B[<b_row_index>,<b_col_index>]\n",
    "    \n",
    "    # 4\n",
    "    # return the 2D numpy array for C\n",
    "    return C\n",
    "```\n",
    "    \n",
    "6. Discuss your results in the markdown cell that follows your codes include in your discussion remarks about the questions asked in the markdown cell.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Write function definitions for Exercise 2 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4dc104d3",
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Define your functions for Exercise 2 here.\n",
    "\n",
    "@numba.njit(cache=True, fastmath=True, nogil=True)\n",
    "def numba_matmul_1(A:np.ndarray, B:np.ndarray):\n",
    "    \"\"\" This is a Numba accelerated matrix-multiplication function \"\"\"  \n",
    "    \"\"\" Index order: ijk (i loops over N, j loops over M, k loops over K)\"\"\"\n",
    "    \n",
    "    N, K = A.shape\n",
    "    _K, M = B.shape\n",
    "    \n",
    "    if K != _K:\n",
    "        raise ValueError('Matrices dimensions do not match for multiplication!')\n",
    "    \n",
    "    C = np.zeros((N, M), dtype=A.dtype)\n",
    "    \n",
    "    for i in numba.prange(N):\n",
    "        for j in range(M):\n",
    "            for k in range(K):\n",
    "                C[i, j] += A[i, k] * B[k, j]\n",
    "    \n",
    "    return C\n",
    "\n",
    "\n",
    "@numba.njit(cache=True, fastmath=True, nogil=True)\n",
    "def numba_matmul_2(A:np.ndarray, B:np.ndarray):\n",
    "    \"\"\" This is a Numba accelerated matrix-multiplication function \"\"\"  \n",
    "    \"\"\" Index order: ikj (i loops over N, j loops over M, k loops over K)\"\"\"\n",
    "    \n",
    "    N, K = A.shape\n",
    "    _K, M = B.shape\n",
    "    \n",
    "    if K != _K:\n",
    "        raise ValueError('Matrices dimensions do not match for multiplication!')\n",
    "    \n",
    "    C = np.zeros((N, M), dtype=A.dtype)\n",
    "    \n",
    "    for i in numba.prange(N):\n",
    "        for k in range(K):\n",
    "            for j in range(M):\n",
    "                C[i, j] += A[i, k] * B[k, j]\n",
    "    \n",
    "    return C\n",
    "\n",
    "\n",
    "@numba.njit(cache=True, fastmath=True, nogil=True)\n",
    "def numba_matmul_3(A:np.ndarray, B:np.ndarray):\n",
    "    \"\"\" This is a Numba accelerated matrix-multiplication function \"\"\"  \n",
    "    \"\"\" Index order: jik (i loops over N, j loops over M, k loops over K)\"\"\"\n",
    "    \n",
    "    N, K = A.shape\n",
    "    _K, M = B.shape\n",
    "    \n",
    "    if K != _K:\n",
    "        raise ValueError('Matrices dimensions do not match for multiplication!')\n",
    "    \n",
    "    C = np.zeros((N, M), dtype=A.dtype)\n",
    "    \n",
    "    for j in numba.prange(M):\n",
    "        for i in range(N):\n",
    "            for k in range(K):\n",
    "                C[i, j] += A[i, k] * B[k, j]\n",
    "    \n",
    "    return C\n",
    "\n",
    "\n",
    "@numba.njit(cache=True, fastmath=True, nogil=True)\n",
    "def numba_matmul_4(A:np.ndarray, B:np.ndarray):\n",
    "    \"\"\" This is a Numba accelerated matrix-multiplication function \"\"\"  \n",
    "    \"\"\" Index order: jki (i loops over N, j loops over M, k loops over K)\"\"\"\n",
    "    \n",
    "    N, K = A.shape\n",
    "    _K, M = B.shape\n",
    "    \n",
    "    if K != _K:\n",
    "        raise ValueError('Matrices dimensions do not match for multiplication!')\n",
    "    \n",
    "    C = np.zeros((N, M), dtype=A.dtype)\n",
    "    \n",
    "    for j in numba.prange(M):\n",
    "        for k in range(K):\n",
    "            for i in range(N):\n",
    "                C[i, j] += A[i, k] * B[k, j]\n",
    "    \n",
    "    return C\n",
    "\n",
    "\n",
    "@numba.njit(cache=True, fastmath=True, nogil=True)\n",
    "def numba_matmul_5(A:np.ndarray, B:np.ndarray):\n",
    "    \"\"\" This is a Numba accelerated matrix-multiplication function \"\"\"  \n",
    "    \"\"\" Index order: kij (i loops over N, j loops over M, k loops over K)\"\"\"\n",
    "    \n",
    "    N, K = A.shape\n",
    "    _K, M = B.shape\n",
    "    \n",
    "    if K != _K:\n",
    "        raise ValueError('Matrices dimensions do not match for multiplication!')\n",
    "    \n",
    "    C = np.zeros((N, M), dtype=A.dtype)\n",
    "    \n",
    "    for k in numba.prange(K):\n",
    "        for i in range(N):\n",
    "            for j in range(M):\n",
    "                C[i, j] += A[i, k] * B[k, j]\n",
    "    \n",
    "    return C\n",
    "\n",
    "\n",
    "@numba.njit(cache=True, fastmath=True, nogil=True)\n",
    "def numba_matmul_6(A:np.ndarray, B:np.ndarray):\n",
    "    \"\"\" This is a Numba accelerated matrix-multiplication function \"\"\"  \n",
    "    \"\"\" Index order: kji (i loops over N, j loops over M, k loops over K)\"\"\"\n",
    "    \n",
    "    N, K = A.shape\n",
    "    _K, M = B.shape\n",
    "    \n",
    "    if K != _K:\n",
    "        raise ValueError('Matrices dimensions do not match for multiplication!')\n",
    "    \n",
    "    C = np.zeros((N, M), dtype=A.dtype)\n",
    "    \n",
    "    for k in numba.prange(K):\n",
    "        for j in range(M):\n",
    "            for i in range(N):\n",
    "                C[i, j] += A[i, k] * B[k, j]\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e8b072a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for testing\n",
    "\n",
    "def test_numba_matmul(shape, dtype=np.float64):\n",
    "    \"\"\" This function compares numba matrix-multiplication with np.dot() \"\"\"\n",
    "    \"\"\" Numba functions have 6 permutations of indices \"\"\"\n",
    "\n",
    "    # 1.\n",
    "    # Check the shape of matrix\n",
    "    if shape[0] == shape[1] and shape[1] == shape[2]:\n",
    "        print('Square matrices, N = %d' %shape[0])\n",
    "    else:\n",
    "        print('Non-square matrices, N = %d, K = %d, M = %d' %(shape[i] for i in range(3)))\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    # 2.\n",
    "    # Generate random matrices\n",
    "    A = np.random.rand(shape[0], shape[1]).astype(dtype)\n",
    "    B = np.random.rand(shape[1], shape[2]).astype(dtype)\n",
    "    \n",
    "    # 3. \n",
    "    # Reference result from np.dot()\n",
    "    t_start = time()\n",
    "    C_ref = np_matmul(A, B)\n",
    "    t_end = time()\n",
    "    t_ref = t_end - t_start\n",
    "\n",
    "    # 4.\n",
    "    # Loop over all numba functions. Record runtime with respect to np.dot()\n",
    "    numba_func_list = [numba_matmul_1, numba_matmul_2, numba_matmul_3, \\\n",
    "                       numba_matmul_4, numba_matmul_5, numba_matmul_6]\n",
    "    Nfunc = len(numba_func_list)\n",
    "    numba_runtime = np.zeros((Nfunc, 1))\n",
    "\n",
    "    for i in range(Nfunc):\n",
    "        \n",
    "        t_start = time()\n",
    "        C = numba_func_list[i](A, B)\n",
    "        t_end = time()\n",
    "        \n",
    "        numba_runtime[i] = t_end - t_start\n",
    "    \n",
    "    # 5.\n",
    "    # Output error\n",
    "    print('Error: %s' %(compare_matmul(C, C_ref)))\n",
    "    print()\n",
    "    \n",
    "    # 6.\n",
    "    # Find the fastest numba method and compare with np.dot()\n",
    "    ind_best = np.argmin(numba_runtime)\n",
    "    numba_runtime_best = numba_runtime[ind_best]\n",
    "    \n",
    "    if (numba_runtime_best >= t_ref):\n",
    "        print('Fastest method: np.dot()')\n",
    "        print('Best Numba permutation: %s' %(numba_func_list[ind_best].__name__))\n",
    "        print('Speed-up over Numba functions: %s' %(\", \".join(\"%.2f\" % obj for obj in numba_runtime / t_ref)))\n",
    "    else:\n",
    "        print('Fastest method: %s' %(numba_func_list[ind_best].__name__))\n",
    "        print('Speed-up over np.dot: %s' %(t_ref / numba_runtime_best))\n",
    "        print('Speed-up over Numba functions: %s' %(\", \".join(\"%.2f\" % obj for obj in numba_runtime / numba_runtime_best)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cf9a40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for testing\n",
    "\n",
    "def test_numba_naive(shape, numba_func, dtype=np.float64):\n",
    "    \"\"\" This function compares naive matrix-multiplication with Numba permutation function \"\"\"\n",
    "\n",
    "    # 1.\n",
    "    # Check the shape of matrix\n",
    "    if shape[0] == shape[1] and shape[1] == shape[2]:\n",
    "        print('Square matrices, N = %d' %shape[0])\n",
    "    else:\n",
    "        print('Non-square matrices, N = %d, K = %d, M = %d' %(shape[0], shape[1], shape[2]))\n",
    "        \n",
    "    print()\n",
    "        \n",
    "    # 2.\n",
    "    # Generate random matrices\n",
    "    A = np.random.rand(shape[0], shape[1])\n",
    "    B = np.random.rand(shape[1], shape[2])\n",
    "    \n",
    "    # 3.\n",
    "    # Time functions: Naive matrix-multiplication and Numba function\n",
    "    t1_start = time()\n",
    "    C1 = my_naive_matmul(A, B)\n",
    "    t1_end = time()\n",
    "    t1 = t1_end - t1_start\n",
    "\n",
    "    t2_start = time()\n",
    "    C2 = numba_func(A, B)\n",
    "    t2_end = time()\n",
    "    t2 = t2_end - t2_start\n",
    "\n",
    "    # 4.\n",
    "    # Calculate speed-up and accuracy\n",
    "    if (t1 >= t2):\n",
    "        print('%s is faster' %(numba_func.__name__))\n",
    "        speedup = t1 / t2\n",
    "    else:\n",
    "        print('Naive matmul is faster')\n",
    "        speedup = t2 / t1\n",
    "\n",
    "    print('Speed-up factor: %.3f' %speedup)\n",
    "    print('Error: %s' %compare_matmul(C1, C2))\n",
    "    \n",
    "\n",
    "def test_numba_float_type(shape, numba_func):\n",
    "    \"\"\" This function compares Numba permutation function for different data types \"\"\"\n",
    "\n",
    "    # 1.\n",
    "    # Check the shape of matrix\n",
    "    if shape[0] == shape[1] and shape[1] == shape[2]:\n",
    "        print('Square matrices, N = %d' %shape[0])\n",
    "    else:\n",
    "        print('Non-square matrices, N = %d, K = %d, M = %d' %(shape[0], shape[1], shape[2]))\n",
    "        \n",
    "    print()\n",
    "        \n",
    "    # 2.\n",
    "    # Generate random matrices\n",
    "    A = np.random.rand(shape[0], shape[1])\n",
    "    B = np.random.rand(shape[1], shape[2])\n",
    "    \n",
    "    # 3.\n",
    "    # Time functions: Numba function with different data types\n",
    "    t1_start = time()\n",
    "    C1 = numba_func(A.astype(np.float64), B.astype(np.float64))\n",
    "    t1_end = time()\n",
    "    t1 = t1_end - t1_start\n",
    "\n",
    "    t2_start = time()\n",
    "    C2 = numba_func(A.astype(np.float32), B.astype(np.float32))\n",
    "    t2_end = time()\n",
    "    t2 = t2_end - t2_start\n",
    "\n",
    "    # 4.\n",
    "    # Calculate speed-up and accuracy\n",
    "    if (t1 >= t2):\n",
    "        print('Float32 is faster')\n",
    "        speedup = t1 / t2\n",
    "    else:\n",
    "        print('Float64 is faster')\n",
    "        speedup = t2 / t1\n",
    "\n",
    "    print('Speed-up factor: %.3f' %speedup)\n",
    "    print('Difference in results: %s' %compare_matmul(C1, C2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4327e73a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Write the test codes for Exercise 2 in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b6d3d475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square matrices, N = 128\n",
      "\n",
      "Error: 0.0\n",
      "\n",
      "Fastest method: np.dot()\n",
      "Best Numba permutation: numba_matmul_2\n",
      "Speed-up over Numba functions: 6.16, 3.30, 3.86, 28.32, 3.57, 22.11\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Square matrices, N = 256\n",
      "\n",
      "Error: 1.423067885752971e-09\n",
      "\n",
      "Fastest method: np.dot()\n",
      "Best Numba permutation: numba_matmul_2\n",
      "Speed-up over Numba functions: 11.96, 9.21, 12.05, 32.71, 9.54, 32.48\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Square matrices, N = 512\n",
      "\n",
      "Error: 1.578993646944582e-08\n",
      "\n",
      "Fastest method: np.dot()\n",
      "Best Numba permutation: numba_matmul_2\n",
      "Speed-up over Numba functions: 190.83, 74.36, 257.25, 509.03, 77.17, 525.50\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare with np.dot()\n",
    "\n",
    "for N in np.array([128, 256, 512]):\n",
    "    test_numba_matmul([N, N, N], dtype=np.float64)\n",
    "    print('\\n%s\\n' %(\"-\" * 75))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "64889928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square matrices, N = 128\n",
      "\n",
      "numba_matmul_2 is faster\n",
      "Speed-up factor: 521.551\n",
      "Error: 2.772182483568031e-11\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Square matrices, N = 256\n",
      "\n",
      "numba_matmul_2 is faster\n",
      "Speed-up factor: 544.372\n",
      "Error: 2.2304647018245305e-10\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Square matrices, N = 512\n",
      "\n",
      "numba_matmul_2 is faster\n",
      "Speed-up factor: 559.970\n",
      "Error: 1.7797816553866141e-09\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fastest Numba permutation function compared with naive matrix-multiplication\n",
    "\n",
    "for N in np.array([128, 256, 512]):\n",
    "    test_numba_naive([N, N, N], numba_matmul_2, dtype=np.float64)\n",
    "    print('\\n%s\\n' %(\"-\" * 75))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7a6b31f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square matrices, N = 128\n",
      "\n",
      "Float32 is faster\n",
      "Speed-up factor: 1.053\n",
      "Difference in results: 0.06564263418561822\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Square matrices, N = 256\n",
      "\n",
      "Float32 is faster\n",
      "Speed-up factor: 1.036\n",
      "Difference in results: 0.7351486192010128\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Square matrices, N = 512\n",
      "\n",
      "Float32 is faster\n",
      "Speed-up factor: 1.008\n",
      "Difference in results: 8.168771339268773\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fastest Numba permutation function, compare different float types\n",
    "\n",
    "for N in np.array([128, 256, 512]):\n",
    "    test_numba_float_type([N, N, N], numba_matmul_2)\n",
    "    print('\\n%s\\n' %(\"-\" * 75))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c61afc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Discussion for Exercise 2\n",
    "1. What do you think is causing the differences in performance between the various permutations?\n",
    "1. Which function is fastest (permutations or numpy.dot)? Why do you think this function is the fastest, and could there be multiple factors involved regarding the superior performance?\n",
    "1. When comparing the matrix-matrix performance between the cases were all matrices had dtype=np.float64 vs.  all matrices having dtype=np.float32, which dtype was fastest? Roughly what was the speedup when using this dtype vs the other?\n",
    "1. Does Amdahl's Law play a major factor in the performance differences? Which part of the matrix-matrix multiplication was not parallelized (serial portion)? (Hint: which matrices did we reuse for each function?) Could we parallelize this part, and if so, are there caveats?\n",
    "1. Do you think all codes should be parallelized? What about matrix-matrix multiplication? (This is a subjective question, but I am looking for a brief, but rational and informed arguement).\n",
    "1. For those taking the class for **4 units**: Regarding the performance differences, which Law do you think is more relevant when comparing the performance differences between each of the functions in this exercise, Amdahl's Law or Gustafson's Law? Explain your reasoning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5170b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
